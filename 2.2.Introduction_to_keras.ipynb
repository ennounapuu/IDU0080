{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.2.Introduction_to_keras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"y_AAtw-6a4to","colab_type":"text"},"cell_type":"markdown","source":["#**2.2 Introduction to Keras**\n","\n","##**2.2.1.a Keras**\n","\n","Keras is deep neural network library written in Python which supports user friendliness, modularity and extensibility.  It provide friendly high-level neural networks API that can be used as an efficient tool to design deep-learning models rapidly. In addition, the built-in support provided keras allows us to easily prototype convolutional network, recurrent networks and combination of both. In fact, it hides the details of implementing backpropagation and help to write optimize procedure.\n","\t\n","Keras is a deep learning framework that provides high level building blocks for to define, develop and deploy deep-learning models. In Keras, building model is just stacking layers and connecting computational graphs. One can easily create new module and models can be added quickly in existing model.\n","\n","Keras generally focuses on neural network but it can be used to model Generative Adversarial Network (GAN) and neural Turing Machine as it supports arbitrary network architectures: multi-input or multi-output models, layer sharing,and model sharing.\n","\n","In other hand, keras is dependent on a specialized, well-optimized tensor library. This library acts as the backend engine of keras and handles complex computation on background. Low-level operations such as differentiation and tensor manipulation also control by this tensor library.\n","\n","Keras uses various kind of backend engines such as TensorFlow, Theano and Microsoft Cognitive Toolkit ( CNTK ) as shown in figure 1. Keras is able to run smoothly on both CPUs( tensorFlow itself muffle a low-level library for tensor operations ) and GPUs( TensorFlow muffles  the NVIDIA CUDA Deep Neural Network library). \n","\n","\n","![alt text](https://cdn-images-1.medium.com/max/1600/1*OxAgYCBDKyXYLiWWUoKUcQ.png)\n","\n","    Figure 1: Keras capable of running on top of TensorFlow, CNTK, or Theono\n","\n","\n"]},{"metadata":{"id":"P2Nj_0UR2X8u","colab_type":"text"},"cell_type":"markdown","source":["## **2.2.1.b Tensorflow**\n","   Tensorflow is a deep learning library for numerical computation using data flow graphs recently opened source by Google in November 2015 under the Apache 2.0 license. It is complex machine learning framework that perform distributed mathematical operation in terms of graph. Although other deep learning library such as Theano, Microsoft Cognitive Toolkit (CNTK), Caffe,pyTorch are available, the hype of tensorflow is high above them because of its flexibility and scalability for research and production.\n","\n","TensorFlow supports many  large-scale Machine Learning applications. Such application \n","can be train and deploy efficiently by distributing the numerical computation over thousands of multi-GPU servers.TensorFlow provides primitives for defining functions on tensors and automatically computing their derivatives. Tensor are nothing but geometrics objects having shape, rank, and type used to hold multidimensional arrays.\n","\n","Tensorflow is independent to any software platform(Linux,MacOS,Unix,Windows) and also can be used in mobile devices both iOS and android. The library is implemented in C++, also provide C++ API    needed to build neural networks and offers convenient Python API as well. Moreover, it provide wide range of Python API which are listed below:\n","\n","a. TFLearn in sync with Scikit-Learn - tensorflow.contrib.learn\n","\n","b. TF-Slim, lightweight library for defining, training and evaluating neural network - tensorflow.contrib.slim\n","\n","c. Keras, high level API build on the top of Tensorflow - tensorflow.contrib.keras\n","\n","![alt text](https://www.tensorflow.org/images/tensorflow_programming_environment.png)\n","\n","    Figure 2:  Illustration of tensorflow API in different level\n"]},{"metadata":{"id":"N9NWGxsnf1uH","colab_type":"text"},"cell_type":"markdown","source":["We define  the computation problem in terms of graphs  in python. Tensorflow uses optimezed C++ code in oder to compute the graph and run it efficiently. The whole graph can be divided into smaller units and can be run across multiple CPUs or GPUs parallelly.\n","\n","![alt text](https://www.simplilearn.com/ice9/free_resources_article_thumb/computational-graphs-for-tensorflow-operations.jpg)\n","\n","\n","![alt text](https://www.simplilearn.com/ice9/free_resources_article_thumb/computational-graph-broken-into-chunks-for-parallel-computing.jpg)\n","\n","               Figure 3: Tensorflow: Graph Illustration"]},{"metadata":{"id":"gRhMO8YDs4xR","colab_type":"text"},"cell_type":"markdown","source":["#2.2.2 Developing With Keras\n","## 2.2.2.a Installing Keras \n","\n","\n","As we already discuss  Keras run over on the top of backend engines: Tensorflow, Theano, or CNTK. So we have to install one of its backend engine before installing Keras.\n","\n","*   [TensorFlow installation instructions](https://www.tensorflow.org/install/)\n","*   [CNTK installation instructions.](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine)\n","*   [Theano installation instructions](http://deeplearning.net/software/theano/install.html#install)\n","\n","Keras can be install in two way:\n","\n","\n","1.   Install Keras from PyPI (recommended):\n","\n","       sudo pip install keras\n","       \n","2.   You can install keras using following command in your virtualenv:\n","\n","       pip install keras\n","        \n","Besides, Keras can be install from the GIT repository:\n","\n","   git clone https://github.com/keras-team/keras.git\n","   \n","Then, change directory to Keras folder and run the command:\n","\n","  cd keras\n","  \n","  sudo python setup.py install\n","      \n","  Keras uses Tensorflow as it backend engine for tensor computation by default.\n","  \n","  You could also install these optional dependencies:\n","  \n","*   graphviz and pydot (used by visualization utilities to plot model graphs).\n","*   cuDNN (recommended if you plan on running Keras on GPU).\n","*   HDF5 and h5py (required if you plan on saving Keras models to disk).\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"metadata":{"id":"DIm3v3y0t13L","colab_type":"text"},"cell_type":"markdown","source":["## 2.2.2.b Quick Overview\n","\n","Keras include two types of models: Squential Model and Model used with funcitonal API. In fact, models are the basic building blocks of Keras. Before deep diving into complex architecture lets start with the simplest and common network architecture: Squential Model, model only for linear stack of layers. \n","     Lets build a basic deep learning model. The basic steps are depicted here: \n","     \n","   ![alt text](https://cdn-images-1.medium.com/max/1600/1*uaE9vcY1M2-RTCpurKr9lg.png)\n","   \n","         Figure 4: Illustration of steps in deep learning models\n","   \n","   **i**.** Define A Model** \n","   \n","   Lets define a squential model.\n","   \n","   First, define the input layer. In this model, the input dim argument i.e the independent variable is set to 10 and passed to the first hidden  layer. The first hidden layer consist of 50 neuron with the relu activation fuction.\n","   \n","   Similarly, there are 20 neurons in the second  hidden layer with softmax activation function.\n","   \n","  \n"]},{"metadata":{"id":"7AZgp48pz0k0","colab_type":"code","outputId":"03600f5d-d691-457a-8322-5a20fbd28a80","executionInfo":{"status":"ok","timestamp":1548496138804,"user_tz":-345,"elapsed":2496,"user":{"displayName":"Kiran Bohaju","photoUrl":"","userId":"16397181891022442271"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","\n","\n","model = models.Sequential()\n","model.add(layers.Dense(50, activation='relu', input_dim=10))\n","model.add(layers.Dense(20, activation='softmax'))\n","model.summary()\n","model.to_json()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 50)                550       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 20)                1020      \n","=================================================================\n","Total params: 1,570\n","Trainable params: 1,570\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 10], \"dtype\": \"float32\", \"units\": 50, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 20, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"TpA2CgOL-s3q","colab_type":"text"},"cell_type":"markdown","source":["**ii.Compile Model**\n","   \n","   We are ready to configure the model for training process at this stage. Now lets specify the loss function and optimizer for the model for the learning process. Various options are available for loss function such as mean_squared_error, categorical_crossentropy and similarly for optimizer such as sgd, adam. We are using mean_squared_error as loss function and adam as the optimizer. In addition, here metrics: accuracy is used to monitor model's performance.  \n","  "]},{"metadata":{"id":"yrbGH3Rc-wPL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compile model\n","model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CooDv2SU_ANh","colab_type":"text"},"cell_type":"markdown","source":["**iii. Fit Model**\n","\n","Finally, the last step of learing process is to fit the model via fit() method by passing Numpy array training dataset. Here, we iterate the training for 10 epochs with batch_size=128.."]},{"metadata":{"id":"5Ml17HKBEgB9","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fit Model\n","model.fit(X_train, y_train,batch_size=128, epochs=10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cbVEdZWYGahJ","colab_type":"text"},"cell_type":"markdown","source":["Besides we can make evaluation of our model  and generate prediction on new data."]},{"metadata":{"id":"XtPQ2kRvIwa4","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n","classes = model.predict(x_test, batch_size=128)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7iIuETDe6qvE","colab_type":"text"},"cell_type":"markdown","source":["\n","## 2.2.2.c   Models in Keras\n","\n","In keras, models can be divided in two sub-class:\n","\n","              A. Sequential Model\n","              B. Functional Model\n","\n","Various methods and attributes are associated with the models which are explained below:\n","\n"," #### 1.   model.layers\n","      \n","   It is a flattened list of the layers which is composed of models.\n","\n","#### 2.   model.inputs\n","   It is the list of input tensors of the model. Tensors are multidimensional matrix which are fundamental building blocks of neural networks.\n","      \n","#### 3.  model.outputs\n","It is the list of output tensors of the model.\n","\n","#### 4. model.get_config()\n","This function returns a dictionary containing the configuration of the model. \n","\n","#### 5.   model.summary() \n","This function prints a concise description of our model.\n","\n","#### 6. model.to_json()\n","This method is used to render the configuration of the model as a JSON string. It only returns the architectural presentation, weights are excluded. \n","\n","#### 7. model.to_yaml()\n","This function renders a representation of the model as a YAML string. As model.to_json(), it only returns the architectural presentation, weights are excluded. \n","\n","#### 8. model.get_weights()\n","A list of all weight tensors in the model is return by this method, as Numpy arrays.\n","\n","\n","#### 9.model.set_weights(weights) \n","This method is to used to sets the values of the weights of the model, from a list of Numpy  arrays.\n","The shape of arrays in the list  should be same as that of function model.get_weights().\n","\n","#### 10. model.save_weights(filepath) \n","The weights of the model  are saved as a HDF5 file using this function .\n","\n","#### 11. model.load_weights(filepath, by_name=False)\n","This method loads the weights of the model( from a HDF5 file ) created by save_weights.  We can load weights into a different architecture having some layers in common. Load only those layers with the same name using by_name=True . But the architecture is assumed to be unchanged by default.\n","\n","\n","###   A. Sequential Model\n","   \n","####   1. Model Definition\n","   \n","   Sequential Model is a simple model in which different models  are pile up together one over another similar to stack of books or plates. Simply, we stack layers one by one in linear pipeline.\n","   \n","  Previously, in chapter Quick Overview, we define  sequential model and add two hidden layer to the model. Now, lets define a sequential model in different way by passing a list of layer instances to the constructor. \n","   \n","    \n","   \n","   "]},{"metadata":{"id":"hGLjatpd919i","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","\n","model = Sequential([\n","    Dense(50, input_shape=(70,45,3)),\n","    Activation('relu'),\n","    Dense(20),\n","    Activation('softmax'),\n","])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nju7vI02eNVy","colab_type":"text"},"cell_type":"markdown","source":["#### 1. a Input Shape\n"," \n"," Every  layer has its own unique input and ouptput and each input/ouptput has its own input/output shape. The input shape should be known to the model which is only passed in first layer in order to get knowlegde of shape of input data. In following layes, shapes are calculated automatically.\n"," \n"," In Keras, input shape (input_shape(70,45,3)) takes there parameters as an array of tensor with three dimensions.It ignores the batch size and is able to deal with any batch size. \n"," \n"," But sometime we need to specify the batch size. We can use batch input shape or batch shape (batch_input_shape = (30,70,35,3)) for such cases.\n"," \n"," #### 1.b Activation Functions\n"," \n"," We define a model having dense layer:50 hidden units with relu activations. We should now know that a dense layer with relu activation is illustrated by equation of tensor operation given below:\n"," \n","  **output = relu(dot( W,input ) + b)**   ---------------------  equation(1)\n","  \n"," Here, at this point one may be thinking how to many layers should I use ? or how many hidden units should I use for each layer?.According to the auther of the book \" Deep Learning With Python\", we could follow the following architectural choice.\n","  \n","\n","*   Two intermediate layers with 16 hidden units each\n","*   A third layer that will output the scalar prediction regarding the sentiment of\n","     the current review\n","     \n","     ![alt text](https://cdn-images-1.medium.com/max/1600/1*_vDjHqyZFt383rI46pz7Zg.png)\n","     \n","           Figure 5: Illustration of Activation Function\n","           \n","           \n","           \n"," ##### 1.b.i Importance of Activation Function\n"," \n"," By observing equation (1), one can understand the dense layer just preform a dot product and the addition i.e two linear operation. On the other hand, relu functions consists of non-linear computation.\n"," \n"," It means, if we stick together layers over one by one whether how many, it will still only learn linear implementation of input data: unable to broaden its hypothesis space of the layer ( represents only the set of all possible linear transformations of the input data into a 16-dimensional space).\n"," \n"," So, relu activation function add  the feature of non-linearity to the model. In addition, the hypothesis space is expanded and get advantage from mutliple layer of representation. Besides relu: softmax, prelu, elu,sigmoid and so on are some other example of activation functions.\n"," \n"," \n","\n","\n"," ."]},{"metadata":{"id":"IuxaZlLsb_cd","colab_type":"text"},"cell_type":"markdown","source":["### 2. Compiling The Model\n","\n","Now we are going to train the model for which one need to configure the required  parameter of learning process .\n","\n"]},{"metadata":{"id":"qddiTXWQe2Sg","colab_type":"code","colab":{}},"cell_type":"code","source":["# For a mean squared error regression problem\n","model.compile(optimizer='rmsprop',\n","              loss='mse')\n","\n","# For a binary classification problem\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# For a multi-class classification problem\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QIFwerRKfCvl","colab_type":"text"},"cell_type":"markdown","source":["The model is compile using compile() function. Here one can three parameters optimizer, loss and metrics are passed to each model. Loss function and optimizer are mandatory and for optional evaluation metrics like accuracy is used.\n","\n","#### 2.a Loss Function \n","\n","Loss function is an objective function that sole purpose is to optimize the model.It can be defined in a two way:\n","\n","1.   From Keras losses module, one can import a specific loss fuction e.g mean squared error (mse)      This is the recommended way. \n","\n","          from keras import losses\n","          from keras import metrics\n","          from keras import optimizers\n","\n","          model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","          loss=losses.binary_crossentropy,\n","          metrics=[metrics.binary_accuracy])\n","\n","2.   Simply, we call the respective loss function by name as shown in compiling model\n","\n"," mse, categorical_crossentropy, binary_crossentropy are some of its example\n","\n","\n","#### 2.b  Optimizer\n","\n","The optimizer is used to  minimized the loss function. Optimizers include SGD, RMSprop, and Adam\n","\n","\n","#### 2.c Metrics\n","\n","\n","A metric is also similar to objective function which is used to evaluate the accuracy of your model."]},{"metadata":{"id":"lNzoQdKbkmoI","colab_type":"text"},"cell_type":"markdown","source":["### 3.Training the model\n","\n","The Keras model need to train now for which fit() method is used. A number of arguments can be pass on fit() function which is illustrated below:\n","\n","fit(x=None, y=None, batch_size=None, epochs=1, verbose=1,\n","    callbacks=None,validation_split=0.0, validation_data=None,\n","    shuffle=True, class_weight=None,      sample_weight=None, \n","    initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n","\n","\n","\n","#### 1.  x\n","\n","By default, x can be 'none' as backend engine Tensorflow provide framwork- native-tensors. Training data can be either a Numpy array: incase model has a single input or a list of Numpy array: incase model has a multiple inputs.\n","\n","#### 2.  y\n","y can be 'none' as backend engine Tensorflow provide framwork- native-tensors by default. Target label  data can be either a Numpy array: incase model has a single oupput or a list of Numpy array: incase model has a multiple outputs.\n","\n","#### 3. batch_size\n","\n","It can be either Integer or None. Batch_size will default to 32 if it is not specified. batch_size refers to number of samples per gradient update.\n","\n","#### 4.  epochs\n","The repitation over the entire x training data and y targeted data provided is know as epochs. It is an integer i.e number of iterations to train the model. One can notice both 'initial_epoch','epochs' in above fit() function. The intervel between  'initial_epoch' and 'epochs' gives final epochs.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"metadata":{"id":"GjYBla1nnOJU","colab_type":"code","colab":{}},"cell_type":"code","source":["# For a single-input model with 2 classes (binary classification):\n","\n","model = Sequential()\n","model.add(Dense(32, activation='relu', input_dim=100))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Generate dummy data\n","import numpy as np\n","data = np.random.random((1000, 100))\n","labels = np.random.randint(2, size=(1000, 1))\n","\n","# Train the model, iterating on the data in batches of 32 samples\n","model.fit(data, labels, epochs=10, batch_size=32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UmWTOc5qn9rp","colab_type":"text"},"cell_type":"markdown","source":["## B. Keras Functional Model API\n","\n","\n","  Before starting Keras functional model API, one should better understand the core concept to squential model. This model API is more flexible than the squential model and is used to define complex model i.e model with multiple inputs , combined models or directed acyclic graphs. Wide and Deep Learnings are the best use case for implementing Keras functional model API.\n","  \n","  Let us build a simple densely-connected network using functional model API:\n","  \n","####  1.  Densely-connected network\n","\n","Here lets define a layer instance as 'inputs (input tensor)'. This layer instance is callable and returns a tensor. We can define both input tensor and output according to our requirement to define a model.\n","The model is trained just like the sequential model here.\n","\n","  \n","  "]},{"metadata":{"id":"W8sDegTk1vEX","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","\n","# This returns a tensor\n","inputs = Input(shape=(784,))\n","\n","# a layer instance is callable on a tensor, and returns a tensor\n","x = Dense(64, activation='relu')(inputs)\n","x = Dense(64, activation='relu')(x)\n","predictions = Dense(10, activation='softmax')(x)\n","\n","# This creates a model that includes\n","# the Input layer and three Dense layers\n","model = Model(inputs=inputs, outputs=predictions)\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(data, labels)  # starts training"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N5YEhnEm2G7v","colab_type":"text"},"cell_type":"markdown","source":["#### 2. All models are callable, just like layers\n","\n","The trained models are made callable just as callable layer instance. So, we can reuse the models with Keras functional models. This feature helps to create models which can manipulate the sequences of inputs. You could turn speech recognization model into a speech synthesis model, isn't it sound great? Obviuosly Yes. We have to remember that the architecture of the model and its weights are used by simply calling a model.\n","\n"]},{"metadata":{"id":"ZzJvhyo06G7p","colab_type":"code","colab":{}},"cell_type":"code","source":["#simple callabel model\n","x = Input(shape=(784,))\n","# This works, and returns the 10-way softmax we defined above.\n","y = model(x)\n","\n","\n","# another callabel model using TimeDistributed method\n","from keras.layers import TimeDistributed\n","\n","# Input tensor for sequences of 20 timesteps,\n","# each containing a 784-dimensional vector\n","input_sequences = Input(shape=(20, 784))\n","\n","# This applies our previous model to every timestep in the input sequences.\n","# the output of the previous model was a 10-way softmax,\n","# so the output of the layer below will be a sequence of 20 vectors of size 10.\n","processed_sequences = TimeDistributed(model)(input_sequences)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gqtfF9tP630Z","colab_type":"text"},"cell_type":"markdown","source":["Similarly, multi-input and multi-output models, inception model, shared vision model, residual connection on a convolution layer are other examples of Keras functional models API.\n","\n","\n","\n","## Deep learning workstation : Jupyter Notebooks and Getting Keras running\n","### Jupyter Notebooks\n","The Jupyter Notebook is an open standard, open-source web application which sole purpose is  to create, edit and share notebook documents using web browser. The Jupyter Notebook App, a server-client application that allows data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n","\n"," Deep-learning experiments can be run efficiently using Jupyter Notebooks. It allow us to breakdown the large deep-learning projects to into sub-modules. Each modules can be run independently. So, we don't need to run the whole code if error occurs while running the code. This makes the development process efficient and interactive.Thats why Jupyter Notebook is highly recommended to get started with Keras although various options are available.\n"," \n"," ![alt text](https://cdn-images-1.medium.com/max/1600/1*LPnY8nOLg4S6_TG0DEXwsg.png)\n"," \n"," #### Installing Jupyter Notebook\n"," #### a.Using pip\n","   Install the Jupyter Notebook using:\n"," \n","    pip3 install jupyter\n","  \n","  \n","  #### Running the Notebook\n","  \n"," 1. Basic Step\n"," \n","\n","*   Run the following command to start the notebook server\n","        jupyter notebook\n","*   Now your notebook is ready on your browser.When the notebook opens in your browser, you will see the Notebook Dashboard. It consists of a list of the notebooks, files, and subdirectories in the directory where the notebook server was started.\n","![alt text](https://jupyter.readthedocs.io/en/latest/_images/tryjupyter_file.png)\n","\n","\n"," \n","### Getting Keras Running\n","\n","There are various options to get starte with Keras as we discuss before. Here we suggest one of the following two options:\n","\n","1.   On Unix workstation, install everything form scratch. Then you can run either python codebase or Jupyter notebooks. Follow this option if you already have a high-end NIVIDIA GPU on your local machine.\n","2.   As an second option, run Keras projects as Jupyter Notebooks on EC2. We recomment to use the official EC2 Deep Learning AMI. Follow this option if you don't a have  GPU on your PC/Laptop.\n","\n"]}]}